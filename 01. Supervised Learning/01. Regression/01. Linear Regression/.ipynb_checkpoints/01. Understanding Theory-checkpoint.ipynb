{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ecded6e",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0259b95e",
   "metadata": {},
   "source": [
    "    Linear Regression is predicting the continuous value by understanding the linear relationship between predictor and response variable.\n",
    "    \n",
    "    LR is parametric model where we deal with assumption.\n",
    "    \n",
    "    Two types of LR :\n",
    "        Simple Linear Regression\n",
    "$$y = α + β x$$\n",
    "\n",
    "        Multiple Linear Regression\n",
    "        \n",
    "$$y = α + β_1 x_1 + β_2 x_2 + β_3 x_3 +...+β_q x_q$$      \n",
    "\n",
    "    Parameters LR :\n",
    "        α : intercept | β : Coefficent of Regression\n",
    "        y --> variable(Dependent | Response | Outcome)\n",
    "        x --> variable(Independent | Predictor | Explanatory) \n",
    "    \n",
    "    Statistical Method Estimation : \n",
    "        OLS(Ordinal Least Square)\n",
    "        \n",
    "    Optimal Method Estimation :\n",
    "        Gradient Descent\n",
    "        \n",
    "---        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503df1d6",
   "metadata": {},
   "source": [
    "    OLS(Ordinal Least Square)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971982d9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8024e1ed",
   "metadata": {},
   "source": [
    "    Assumption of Linear Regression\n",
    "    \n",
    "        Linearity\n",
    "        \n",
    "        Normality\n",
    "        \n",
    "        No Multicollinearity\n",
    "        \n",
    "        Homoscedasticity\n",
    "        \n",
    "        No Autocorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cde38be",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d199be",
   "metadata": {},
   "source": [
    "    Linearity : \n",
    "        Understanding the linear association between each predictor with response variable.\n",
    "        \n",
    "        With Pearson's R Correlation, we can find the relation whether they are strongly or weakly correlated or not.\n",
    "        \n",
    "        Graphically we can visualize with scatter plot!        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8749e97",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f618e93",
   "metadata": {},
   "source": [
    "    Normality : \n",
    "        Reponse Variablie should be Normal Distributed  with Mean μ and Variance σ2.\n",
    "        \n",
    "        Residual | Error should be Normal Distributed  with Mean μ = 0 and Variance σ2.\n",
    "        \n",
    "        Graphically we can visualize with kdeplot or displot!\n",
    "        \n",
    "        Measure :\n",
    "            Anderson Darling Test\n",
    "            \n",
    "            Shapiro-Wilk Test\n",
    "            \n",
    "        When above measure fails, we have to transform the data to make it normal distributed.\n",
    "        \n",
    "        Transformation :\n",
    "            BOX-COX transformation\n",
    "            \n",
    "            Yeo-Johnson(data point are -ve) transformation\n",
    "            \n",
    "            Log transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2204fe",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ecbc14",
   "metadata": {},
   "source": [
    "    No Multicollinearity :\n",
    "        There should no correlation among independent variable. If we have multicollinearity then we get false significance.\n",
    "        \n",
    "        With Correlation, we can find the relation whether they are strongly or weakly correlated with each other or not.\n",
    "        \n",
    "        Measure :\n",
    "            Correlation \n",
    "            \n",
    "            Variance Inflation Factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbe382d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34070c5b",
   "metadata": {},
   "source": [
    "    Homoscedasticiy : \n",
    "        Checks for Same Spreadness\n",
    "        \n",
    "        Meaning variance of error or residual should be statistically equal to zero\n",
    "        Measure : \n",
    "            Breusch Pagan Test\n",
    "                Ho: Homoscedasticity exists (constant variance of residuals).\n",
    "                Ha: Heteroscedasticity exists (non-constant variance of residuals)\n",
    "\n",
    "            \n",
    "            Goldfeld Quandt Test\n",
    "                Ho: Homoscedasticity (equal variance)\n",
    "                Ha: Heteroscedasticity (unequal variance)\n",
    "                \n",
    "```python\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.diagnostic import het_goldfeldquandt\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Perform the Goldfeld-Quandt test\n",
    "gq_test = het_goldfeldquandt(model.resid, X)\n",
    "print(\"F-statistic:\", gq_test[0])\n",
    "print(\"p-value:\", gq_test[1])\n",
    "print(\"The null hypothesis of homoscedasticity is rejected if p-value < 0.05\")\n",
    "\n",
    "```\n",
    "            \n",
    "            White Test\n",
    "                Ho: Homoscedasticity\n",
    "                Ha: Heteroscedasticity\n",
    "```python\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.diagnostic import het_white\n",
    "\n",
    "# Fit your regression model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Calculate residuals\n",
    "residuals = model.resid\n",
    "\n",
    "# Get independent variables for White test\n",
    "exog = model.model.exog\n",
    "\n",
    "# Perform White test\n",
    "white_test = het_white(residuals, exog)\n",
    "print(\"White Test Results:\")\n",
    "print(\"LM Statistic:\", white_test[0])\n",
    "print(\"LM-Test p-value:\", white_test[1])\n",
    "print(\"F-Test p-value:\", white_test[2])\n",
    "print(\"Degrees of Freedom:\", white_test[3])\n",
    "```\n",
    "            \n",
    "            NCV test(non-constant variance)\n",
    "                Ho: Homoscedasticity(variance of the errors (residuals) is constant)\n",
    "                Ha: Heteroscedasticity\n",
    "                \n",
    "                \n",
    "```python\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.compat import lzip\n",
    "from statsmodels.stats.diagnostic import het_goldfeldquandt\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "# Perform the Goldfeld-Quandt test for non-constant variance\n",
    "name = ['F statistic', 'p-value']\n",
    "test = het_goldfeldquandt(results.resid, X)\n",
    "print(lzip(name, test))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c62453c",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f961b7e",
   "metadata": {},
   "source": [
    "    No Autocorrelation : \n",
    "        No correlation on observation of Dependent Variable. \n",
    "        \n",
    "        \n",
    "        Measure :\n",
    "            Durbin Watson Test\n",
    "                Ho is significant we use linear regression\n",
    "                Ha is significant then use Time series\n",
    "                \n",
    "```python\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "\n",
    "# Perform Durbin-Watson test for autocorrelation in residuals\n",
    "dw_statistic = durbin_watson(results.resid)\n",
    "print(\"Durbin-Watson statistic:\", dw_statistic)\n",
    "```\n",
    "\n",
    "    Interpretation of Durbin-Watson test :\n",
    "        Test statistic ~ 2, => no significant autocorrelation.\n",
    "        Test statistic is significantly < 2 (approaching 0), it suggests positive autocorrelation.\n",
    "        Test statistic is significantly > 2 (approaching 4), it suggests negative autocorrelation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
