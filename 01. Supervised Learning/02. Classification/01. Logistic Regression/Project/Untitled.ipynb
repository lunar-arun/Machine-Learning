{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e067fbc",
   "metadata": {},
   "source": [
    "    Vaccine Usage Prediction\n",
    "    \n",
    "    Abstract:\n",
    "                    Subjects receiving the same vaccine often show different levels of immune responses and some may even present adverse side effects to the vaccine. Systems vaccinology can combine data and machine learning techniques to obtain highly predictive signatures of vaccine immunogenicity and reactogenicity. Currently, several machine learning methods are already available to researchers with no background in bioinformatics.\n",
    "    \n",
    "    \n",
    "    Problem Statement:\n",
    "        Predict how likely it is that the people will take an H1N1 flu vaccine using Logistic Regression.\n",
    "    \n",
    "    \n",
    "    Dataset Information:\n",
    "    \n",
    "    Column\tDescription\n",
    "        unique_id\tUnique identifier for each respondent\n",
    "    h1n1_worry\tWorry about the h1n1 flu(0,1,2,3) 0=Not worried at all, 1=Not very worried, 2=Somewhat worried, 3=Very worried\n",
    "            h1n1_awareness\tSignifies the amount of knowledge or understanding the respondent has about h1n1 flu - (0,1,2) - 0=No knowledge, 1=little knowledge, 2=good knowledge\n",
    "    antiviral_medication\tHas the respondent taken antiviral vaccination - (0,1)\n",
    "    contact_avoidance\tHas avoided any close contact with people who have flu-like symptoms - (0,1)\n",
    "    bought_face_mask\tHas the respondent bought mask or not - (0,1)\n",
    "    wash_hands_frequently\tWashes hands frequently or uses hand sanitizer - (0,1)\n",
    "    \n",
    "\n",
    "    \n",
    "    avoid_large_gatherings\tHas the respondent reduced time spent at large gatherings - (0,1)\n",
    "    reduced_outside_home_cont\tHas the respondent reduced contact with people outside their own house - (0,1)\n",
    "    avoid_touch_face\tAvoids touching nose, eyes, mouth - (0,1)\n",
    "    dr_recc_h1n1_vacc\tDoctor has recommended h1n1 vaccine - (0,1)\n",
    "    dr_recc_seasonal_vacc\tThe doctor has recommended seasonal flu vaccine - (0,1)\n",
    "    chronic_medic_condition\tHas any chronic medical condition - (0,1)\n",
    "    cont_child_undr_6_mnth\tHas regular contact with child the age of 6 months - (0,1)\n",
    "    is_health_worker\tIs respondent a health worker - (0,1)\n",
    "    has_health_insur\tDoes respondent have health insurance - (0,1)\n",
    "        is_h1n1_vacc_effective\tDoes respondent think that the h1n1 vaccine is effective - (1,2,3,4,5)- (1=Thinks not effective at all, 2=Thinks it is not very effective, 3=Doesn't know if it is effective or not, 4=Thinks it is somewhat effective, 5=Thinks it is highly effective)\n",
    "        is_h1n1_risky\tWhat respondents think about the risk of getting ill with h1n1 in the absence of the vaccine- (1,2,3,4,5)- (1=Thinks it is not very low risk, 2=Thinks it is somewhat low risk, 3=don’t know if it is risky or not, 4=Thinks it is a somewhat high risk, 5=Thinks it is very highly risky)\n",
    "            sick_from_h1n1_vacc\tDoes respondent worry about getting sick by taking the h1n1 vaccine - (1,2,3,4,5)- (1=Respondent not worried at all, 2=Respondent is not very worried, 3=Doesn't know, 4=Respondent is somewhat worried, 5Respondent is very worried) -\n",
    "        is_seas_vacc_effective\tDoes respondent think that the seasonal vaccine is effective- (1,2,3,4,5)- (1=Thinks not effective at all, 2=Thinks it is not very effective, 3=Doesn't know if it\n",
    "    \n",
    "    \n",
    "    \n",
    "\tis effective or not, 4=Thinks it is somewhat effective, 5=Thinks it is highly effective)\n",
    "            is_seas_flu_risky\tWhat respondents think about the risk of getting ill with seasonal flu in the absence of the vaccine- (1,2,3,4,5)- (1=Thinks it is not very low risk, 2=Thinks it is somewhat low risk, 3=Doesn't know if it is risky or not, 4=Thinks it is somewhat high risk, 5=Thinks it is very highly risky)\n",
    "            sick_from_seas_vacc\tDoes respondent worry about getting sick by taking the seasonal flu vaccine - (1,2,3,4,5)- (1=Respondent not worried at all, 2=Respondent is not very worried, 3=Doesn't know, 4=Respondent is somewhat worried, 5Respondent is very worried)\n",
    "    age_bracket\tAge bracket of the respondent - (18 - 34 Years, 35 - 44\n",
    "        Years, 45 - 54 Years, 55 - 64 Years, 64+ Years)\n",
    "        qualification\tQualification/education level of the respondent as per their response -(<12 Years, 12 Years, College Graduate, Some College)\n",
    "    race\tRespondent's race - (White, Black, Other or Multiple\n",
    "    ,Hispanic)\n",
    "        sex\tRespondent's sex - (Female, Male)\n",
    "        income_level\tAnnual income of the respondent as per the 2008 poverty Census - (<=\n",
    "        75000−AbovePoverty,> 75000−AbovePoverty,>75000, Below Poverty)\n",
    "        marital_status\tRespondent's marital status - (Not Married, Married)\n",
    "        housing_status\tRespondent's housing status - (Own, Rent)\n",
    "    employment\tRespondent's employment status - (Not in Labor Force, Employed, Unemployed)\n",
    "        census_msa\tResidence of the respondent with the MSA(metropolitan statistical area)(Non-MSA, MSA- Not Principle, CityMSA-Principle city) - (Yes, no)\n",
    "\n",
    "\n",
    "\n",
    "    no_of_adults\tNumber of adults in the respondent's house (0,1,2,3) - (Yes, no)\n",
    "    no_of_children\tNumber of children in the respondent's house(0,1,2,3)\n",
    "        - (Yes, No)\n",
    "    h1n1_vaccine\tDependent variable)Did the respondent receive the h1n1 vaccine or not(1,0) - (Yes, No)\n",
    "    \n",
    "    \n",
    "    \n",
    "    Scope:\n",
    "    ●Exploratory data analysis\n",
    "    ●Data Pre-processing\n",
    "    ●Training logistic regression model with MLE for prediction\n",
    "    ●Tuning the model to improve the performance\n",
    "    \n",
    "    \n",
    "    Learning Outcome:\n",
    "            The students will get a better understanding of how the variables are linked to each other and how the EDA approach will help them gain more insights and knowledge about the data that we have and train Logistic Regression using MLE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "315be319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "304a9cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Dataset/h1n1_vaccine_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca7db4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       unique_id  h1n1_worry  h1n1_awareness  antiviral_medication  \\\n",
      "0              0         1.0             0.0                   0.0   \n",
      "1              1         3.0             2.0                   0.0   \n",
      "2              2         1.0             1.0                   0.0   \n",
      "3              3         1.0             1.0                   0.0   \n",
      "4              4         2.0             1.0                   0.0   \n",
      "...          ...         ...             ...                   ...   \n",
      "26702      26702         2.0             0.0                   0.0   \n",
      "26703      26703         1.0             2.0                   0.0   \n",
      "26704      26704         2.0             2.0                   0.0   \n",
      "26705      26705         1.0             1.0                   0.0   \n",
      "26706      26706         0.0             0.0                   0.0   \n",
      "\n",
      "       contact_avoidance  bought_face_mask  wash_hands_frequently  \\\n",
      "0                    0.0               0.0                    0.0   \n",
      "1                    1.0               0.0                    1.0   \n",
      "2                    1.0               0.0                    0.0   \n",
      "3                    1.0               0.0                    1.0   \n",
      "4                    1.0               0.0                    1.0   \n",
      "...                  ...               ...                    ...   \n",
      "26702                1.0               0.0                    0.0   \n",
      "26703                1.0               0.0                    1.0   \n",
      "26704                1.0               1.0                    1.0   \n",
      "26705                0.0               0.0                    0.0   \n",
      "26706                1.0               0.0                    0.0   \n",
      "\n",
      "       avoid_large_gatherings  reduced_outside_home_cont  avoid_touch_face  \\\n",
      "0                         0.0                        1.0               1.0   \n",
      "1                         0.0                        1.0               1.0   \n",
      "2                         0.0                        0.0               0.0   \n",
      "3                         1.0                        0.0               0.0   \n",
      "4                         1.0                        0.0               1.0   \n",
      "...                       ...                        ...               ...   \n",
      "26702                     0.0                        1.0               0.0   \n",
      "26703                     0.0                        0.0               0.0   \n",
      "26704                     1.0                        0.0               1.0   \n",
      "26705                     0.0                        0.0               NaN   \n",
      "26706                     0.0                        0.0               0.0   \n",
      "\n",
      "       ...      race     sex               income_level  marital_status  \\\n",
      "0      ...     White  Female              Below Poverty     Not Married   \n",
      "1      ...     White    Male              Below Poverty     Not Married   \n",
      "2      ...     White    Male  <= $75,000, Above Poverty     Not Married   \n",
      "3      ...     White  Female              Below Poverty     Not Married   \n",
      "4      ...     White  Female  <= $75,000, Above Poverty         Married   \n",
      "...    ...       ...     ...                        ...             ...   \n",
      "26702  ...     White  Female  <= $75,000, Above Poverty     Not Married   \n",
      "26703  ...     White    Male  <= $75,000, Above Poverty     Not Married   \n",
      "26704  ...     White  Female                        NaN     Not Married   \n",
      "26705  ...  Hispanic  Female  <= $75,000, Above Poverty         Married   \n",
      "26706  ...     White    Male  <= $75,000, Above Poverty         Married   \n",
      "\n",
      "       housing_status          employment                census_msa  \\\n",
      "0                 Own  Not in Labor Force                   Non-MSA   \n",
      "1                Rent            Employed  MSA, Not Principle  City   \n",
      "2                 Own            Employed  MSA, Not Principle  City   \n",
      "3                Rent  Not in Labor Force       MSA, Principle City   \n",
      "4                 Own            Employed  MSA, Not Principle  City   \n",
      "...               ...                 ...                       ...   \n",
      "26702             Own  Not in Labor Force                   Non-MSA   \n",
      "26703            Rent            Employed       MSA, Principle City   \n",
      "26704             Own                 NaN  MSA, Not Principle  City   \n",
      "26705            Rent            Employed                   Non-MSA   \n",
      "26706             Own  Not in Labor Force       MSA, Principle City   \n",
      "\n",
      "       no_of_adults  no_of_children  h1n1_vaccine  \n",
      "0               0.0             0.0             0  \n",
      "1               0.0             0.0             0  \n",
      "2               2.0             0.0             0  \n",
      "3               0.0             0.0             0  \n",
      "4               1.0             0.0             0  \n",
      "...             ...             ...           ...  \n",
      "26702           0.0             0.0             0  \n",
      "26703           1.0             0.0             0  \n",
      "26704           0.0             0.0             0  \n",
      "26705           1.0             0.0             0  \n",
      "26706           1.0             0.0             0  \n",
      "\n",
      "[26707 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aae921a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d63ca39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unique_id', 'h1n1_worry', 'h1n1_awareness', 'antiviral_medication',\n",
       "       'contact_avoidance', 'bought_face_mask', 'wash_hands_frequently',\n",
       "       'avoid_large_gatherings', 'reduced_outside_home_cont',\n",
       "       'avoid_touch_face', 'dr_recc_h1n1_vacc', 'dr_recc_seasonal_vacc',\n",
       "       'chronic_medic_condition', 'cont_child_undr_6_mnths',\n",
       "       'is_health_worker', 'has_health_insur', 'is_h1n1_vacc_effective',\n",
       "       'is_h1n1_risky', 'sick_from_h1n1_vacc', 'is_seas_vacc_effective',\n",
       "       'is_seas_risky', 'sick_from_seas_vacc', 'age_bracket', 'qualification',\n",
       "       'race', 'sex', 'income_level', 'marital_status', 'housing_status',\n",
       "       'employment', 'census_msa', 'no_of_adults', 'no_of_children',\n",
       "       'h1n1_vaccine'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a571d797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26707 entries, 0 to 26706\n",
      "Data columns (total 34 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   unique_id                  26707 non-null  int64  \n",
      " 1   h1n1_worry                 26615 non-null  float64\n",
      " 2   h1n1_awareness             26591 non-null  float64\n",
      " 3   antiviral_medication       26636 non-null  float64\n",
      " 4   contact_avoidance          26499 non-null  float64\n",
      " 5   bought_face_mask           26688 non-null  float64\n",
      " 6   wash_hands_frequently      26665 non-null  float64\n",
      " 7   avoid_large_gatherings     26620 non-null  float64\n",
      " 8   reduced_outside_home_cont  26625 non-null  float64\n",
      " 9   avoid_touch_face           26579 non-null  float64\n",
      " 10  dr_recc_h1n1_vacc          24547 non-null  float64\n",
      " 11  dr_recc_seasonal_vacc      24547 non-null  float64\n",
      " 12  chronic_medic_condition    25736 non-null  float64\n",
      " 13  cont_child_undr_6_mnths    25887 non-null  float64\n",
      " 14  is_health_worker           25903 non-null  float64\n",
      " 15  has_health_insur           14433 non-null  float64\n",
      " 16  is_h1n1_vacc_effective     26316 non-null  float64\n",
      " 17  is_h1n1_risky              26319 non-null  float64\n",
      " 18  sick_from_h1n1_vacc        26312 non-null  float64\n",
      " 19  is_seas_vacc_effective     26245 non-null  float64\n",
      " 20  is_seas_risky              26193 non-null  float64\n",
      " 21  sick_from_seas_vacc        26170 non-null  float64\n",
      " 22  age_bracket                26707 non-null  object \n",
      " 23  qualification              25300 non-null  object \n",
      " 24  race                       26707 non-null  object \n",
      " 25  sex                        26707 non-null  object \n",
      " 26  income_level               22284 non-null  object \n",
      " 27  marital_status             25299 non-null  object \n",
      " 28  housing_status             24665 non-null  object \n",
      " 29  employment                 25244 non-null  object \n",
      " 30  census_msa                 26707 non-null  object \n",
      " 31  no_of_adults               26458 non-null  float64\n",
      " 32  no_of_children             26458 non-null  float64\n",
      " 33  h1n1_vaccine               26707 non-null  int64  \n",
      "dtypes: float64(23), int64(2), object(9)\n",
      "memory usage: 6.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5eface8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unique_id                        0\n",
       "h1n1_worry                      92\n",
       "h1n1_awareness                 116\n",
       "antiviral_medication            71\n",
       "contact_avoidance              208\n",
       "bought_face_mask                19\n",
       "wash_hands_frequently           42\n",
       "avoid_large_gatherings          87\n",
       "reduced_outside_home_cont       82\n",
       "avoid_touch_face               128\n",
       "dr_recc_h1n1_vacc             2160\n",
       "dr_recc_seasonal_vacc         2160\n",
       "chronic_medic_condition        971\n",
       "cont_child_undr_6_mnths        820\n",
       "is_health_worker               804\n",
       "has_health_insur             12274\n",
       "is_h1n1_vacc_effective         391\n",
       "is_h1n1_risky                  388\n",
       "sick_from_h1n1_vacc            395\n",
       "is_seas_vacc_effective         462\n",
       "is_seas_risky                  514\n",
       "sick_from_seas_vacc            537\n",
       "age_bracket                      0\n",
       "qualification                 1407\n",
       "race                             0\n",
       "sex                              0\n",
       "income_level                  4423\n",
       "marital_status                1408\n",
       "housing_status                2042\n",
       "employment                    1463\n",
       "census_msa                       0\n",
       "no_of_adults                   249\n",
       "no_of_children                 249\n",
       "h1n1_vaccine                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c578216",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m y1 \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh1n1_vaccine\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      6\u001b[0m X_train1, X_test1, y_train1, y_test1 \u001b[38;5;241m=\u001b[39m train_test_split(X1, y1, test_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.3\u001b[39m, random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m36\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m logistic_model_1 \u001b[38;5;241m=\u001b[39m \u001b[43mLogisticRegression\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Check whether how this model fits the data\u001b[39;00m\n\u001b[0;32m     11\u001b[0m predicted_y_train1 \u001b[38;5;241m=\u001b[39m logistic_model_1\u001b[38;5;241m.\u001b[39mpredict(X_train1)\n",
      "File \u001b[1;32mF:\\Applications\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1196\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1194\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[1;32m-> 1196\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1203\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1204\u001b[0m check_classification_targets(y)\n\u001b[0;32m   1205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[1;32mF:\\Applications\\anaconda3\\lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 565\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mF:\\Applications\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1101\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[1;32m-> 1106\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1122\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mF:\\Applications\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    915\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    916\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    917\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    918\u001b[0m         )\n\u001b[0;32m    920\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 921\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    929\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mF:\\Applications\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m     )\n\u001b[1;32m--> 161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "X1 = df.drop(['h1n1_vaccine','age_bracket', 'qualification',\n",
    "       'race', 'sex', 'income_level', 'marital_status', 'housing_status',\n",
    "       'employment', 'census_msa'], axis = 1)\n",
    "y1 = df['h1n1_vaccine']\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size = 0.3, random_state = 36)\n",
    "\n",
    "logistic_model_1 = LogisticRegression().fit(X_train1, y_train1)\n",
    "\n",
    "# Check whether how this model fits the data\n",
    "predicted_y_train1 = logistic_model_1.predict(X_train1)\n",
    "train_accuracy_1 = accuracy_score(y_train1, predicted_y_train1)\n",
    "\n",
    "predicted_y_test1 = logistic_model_1.predict(X_test1)\n",
    "test_accuracy_1 = accuracy_score(y_test1, predicted_y_test1)\n",
    "\n",
    "if train_accuracy_1 > test_accuracy_1 and abs(train_accuracy_1 - test_accuracy_1) < 0.10:\n",
    "    print('Model is slightly overfitting')\n",
    "elif train_accuracy_1 < test_accuracy_1 or abs(train_accuracy_1 - test_accuracy_1) < 0.10:\n",
    "    print('Model is slightly overfitting')\n",
    "elif train_accuracy_1 < 0.7 or test_accuracy_1 < 0.7:\n",
    "    print('Model is underfitting')\n",
    "else:\n",
    "    print('Model is a good fit') \n",
    "    \n",
    "print(f\"Train_accuracy : {train_accuracy_1} \\nTest_accuracy : {test_accuracy_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce24cb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
