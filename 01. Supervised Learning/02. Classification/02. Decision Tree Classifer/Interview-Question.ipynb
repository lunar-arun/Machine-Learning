{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72609ab4",
   "metadata": {},
   "source": [
    "    What is a Decision Tree in machine learning, and how does it work?\n",
    "        It is a supervised learning technique used for both classification and regression tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe1892d",
   "metadata": {},
   "source": [
    "    What is entropy?\n",
    "        It's a measure of impurity or disorder in a dataset. \n",
    "        \n",
    "        A low entropy indicates that the data is pure, meaning all instances in the subset belong to the same class, \n",
    "        while a high entropy suggests that the data is mixed with multiple classes.\n",
    "        \n",
    "        E(S) = − p1 ∗ log2(p1) − p2 ∗log2(p2) − . . . − pn ∗log2(pn)\n",
    "            E(S) is the entropy of the dataset S.\n",
    "            p1, p2, . . . pn are the proportions of different classes in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aa6cab",
   "metadata": {},
   "source": [
    "    what is Information Gain?\n",
    "        Measure of the reduction in entropy.\n",
    "        \n",
    "        A higher information gain implies that using attribute A for splitting leads to a more significant reduction in uncertainty (entropy), making it a good choice for the next split.\n",
    "        \n",
    "        I.G(S, A) = E(S) - Σ (|Sv|/|S|) * E(Sv)\n",
    "            I.G(S, A) is the information gain to achieve for splitting dataset S using A attribute.\n",
    "            E(S) is the entropy of original dataset S.\n",
    "            Sv is the number of instances in dataset S for which attribute A takes the value v.\n",
    "            S is the total number of instances in dataset S."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fa4bab",
   "metadata": {},
   "source": [
    "        By selecting attributes that maximize information gain or minimize impurity, Decision Trees aim to create splits that separate the data into homogeneous subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5815b8",
   "metadata": {},
   "source": [
    "    what is Gini Impurity?\n",
    "         measure of impurity or disorder in dataset.\n",
    "         Gini impurity helps determine the best attribute to split the data at each node of a Decision Tree.\n",
    "          Gini impurity takes values between 0 and 1.\n",
    "          Gini impurity of 0 indicates that the dataset is pure, meaning all elements belong to the same class.\n",
    "          Gini impurity of 1 means that the dataset is completely impure, with elements evenly distributed across all classes.\n",
    "          \n",
    "          Gini Impurtiy : \n",
    "              Gini(S) = 1 - Σ (p)^2\n",
    "          \n",
    "          The attribute with the lowest Gini impurity (or highest Gini gain) is preferred.\n",
    "          \n",
    "          Gini_gain(S, A) = Gini(S) - Σ (|Sv|/|S|) * Gini(Sv)\n",
    "              Gini_gain(S, A) is the Gini gain to achieve for splitting dataset S using A attribute.\n",
    "              Gini(S) is the entropy of original dataset S.\n",
    "              Sv is the number of instances in dataset S for which attribute A takes the value v.\n",
    "              S is the total number of instances in dataset S."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c98ffdb",
   "metadata": {},
   "source": [
    "    What are the advantages?\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941d2bb8",
   "metadata": {},
   "source": [
    "    What are the disadvantages?\n",
    "        Overfitting : \n",
    "            Occur due to capture of noise in the dataset, outliers letting to tree to grow deep or complex.\n",
    "            solution : \n",
    "                Pruning the tree: Pruning involves removing branches that do not significantly improve performance on validation data.\n",
    "                \n",
    "                Setting a maximum depth: Limiting the depth of the tree can prevent it from becoming overly complex."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5fdd2d",
   "metadata": {},
   "source": [
    "    what are the types of Decision Tree Algorithm?\n",
    "        ID3 (Iterative Dichotomiser 3) \n",
    "        \n",
    "        C4.5 (Classification and Regression Trees)\n",
    "        \n",
    "        CART (Classification and Regression Trees)\n",
    "        \n",
    "        CHAID (Chi-Squared Automatic Interaction Detection)\n",
    "        \n",
    "        MARS (Multivariate Adaptive Regression Splines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08acd254",
   "metadata": {},
   "source": [
    "    what is ID3 (Iterative Dichotomiser 3) method?\n",
    "        It uses entropy and information gain as criteria for attribute selection.\n",
    "        ID3 was primarily designed for categorical attributes and binary classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6926ec00",
   "metadata": {},
   "source": [
    "    what is C4.5 (Classification and Regression Trees)?\n",
    "        CART can handle both categorical and numerical attributes and uses Gini impurity as the criterion for classification tasks and mean squared error for regression tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbacfc9a",
   "metadata": {},
   "source": [
    "    what is CHAID (Chi-Squared Automatic Interaction Detection)?\n",
    "        CHAID is primarily used for classification tasks.\n",
    "        CHAID is designed to work with categorical data and creates multiway trees rather than binary trees, making it useful for exploring interactions between multiple attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d08575",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfad7a1f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
