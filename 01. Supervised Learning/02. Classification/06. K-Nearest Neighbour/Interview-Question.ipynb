{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb9a2139",
   "metadata": {},
   "source": [
    "    what is K-Nearest Neighbor(KNN) Algorithm?\n",
    "        It's a non-parametric, supervised learning classifier, which uses proximity to make classifications or predictions about the grouping of an individual data point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ac3313",
   "metadata": {},
   "source": [
    "    Significance of the parameter K in K-NN?\n",
    "         K represents the number of nearest neighbors to consider when making a prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2435470",
   "metadata": {},
   "source": [
    "    How do you choose optimal K in KNN?\n",
    "        The optimal K value usually found is the square root of N, where N is the total number of samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441667f0",
   "metadata": {},
   "source": [
    "    curse of dimensionality and how it relates to K-NN?\n",
    "        increased computational due number of dimensions (features) in the dataset increases.\n",
    "        \n",
    "        In K-NN, high-dimensional data can lead to less meaningful distance measures, requiring careful feature selection or dimensionality reduction techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2567bd",
   "metadata": {},
   "source": [
    "    Difference between K-NN and K-Means clustering?\n",
    "        K-NN is a supervised learning algorithm used for classification and regression\n",
    "        \n",
    "        K-Means is an unsupervised clustering algorithm used for grouping similar data points together based on feature similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e59a72b",
   "metadata": {},
   "source": [
    "     techniques to improve the efficiency of K-NN on large datasets?\n",
    "         PCA (Principal Component Analysis), \n",
    "         utilizing data indexing structures (e.g., KD-Trees or Ball Trees), and \n",
    "         parallelizing computations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0341946",
   "metadata": {},
   "source": [
    "    What is SMOTE?\n",
    "        stands for \"Synthetic Minority Over-sampling Technique\"\n",
    "            A resampling technique to address the class imbalance problem.\n",
    "        This imbalance can lead to biased model training and poor classification performance, as models tend to favor the majority class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f065a0e",
   "metadata": {},
   "source": [
    "    How SMOTE works?\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3be526",
   "metadata": {},
   "source": [
    "    Different distance techniques?\n",
    "        Euclidean Distance:\n",
    "            Measures the straight-line (shortest) distance between two points in Euclidean space. It is widely used in clustering algorithms like K-Means.\n",
    "        Manhattan Distance (L1 Norm):\n",
    "            Computes the sum of the absolute differences between the coordinates of two points. It is often used in feature selection and image processing.\n",
    "        Minkowski Distance:\n",
    "            Generalizes both Euclidean and Manhattan distances by introducing a parameter p. When p=2, it is the Euclidean distance, and when p=1, it is the Manhattan distance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9a99f7",
   "metadata": {},
   "source": [
    "    Difference between ball_tree and kd_tree?\n",
    "        Aspect\t                      Ball Tree                     \tKD-Tree\n",
    "        Data                - Divides into hyper-spheres    - Divides into hyper-rectangles\n",
    "        Complexity          - for high-dimensional data     - for low to medium dimensions\n",
    "        Nearest Neighbor    - efficient for high dimensions - less efficient in high dimensions\n",
    "        Imbalanced Data     - Better handling               - Can be sensitive\n",
    "        Memory Usage        - less memory w.r.t KD-Tree     - use more memory than Ball Tree\n",
    "        Skewed Data         - Robust to skewed distribution - May not perform as well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6751fe38",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d60a88a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45e986ea",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0b51e93",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18964ab9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d3ed2d4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3746c5ac",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
