{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2440d0be",
   "metadata": {},
   "source": [
    "    What is Naive Bayes?\n",
    "        Naive Bayes is a probabilistic machine learning algorithm based on Bayes' theorem. \n",
    "        It is used for classification tasks and assumes that features are conditionally independent, given the class label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346a9a15",
   "metadata": {},
   "source": [
    "    Why naive bayes is called naive?\n",
    "        It's called \"Naive\" because the algorithm makes a simplifying assumption that the features are conditionally independent, which is often an oversimplification in real-world data. Hence, the term \"naive.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d981993b",
   "metadata": {},
   "source": [
    "    How does Gaussian Naive Bayes work, and when is it suitable?\n",
    "        It assumes that features are normally distributed. \n",
    "        It's suitable for continuous data, where you estimate mean and variance for each feature in each class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bddb742",
   "metadata": {},
   "source": [
    "    What is Laplace smoothing?\n",
    "        It's used to handle the issue of zero probabilities for unseen data in a class. \n",
    "        It adds a small value to each count to ensure that no probability becomes zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99797e89",
   "metadata": {},
   "source": [
    "    The Zero-Frequency Problem?\n",
    "        An approach to overcome this 'zero-frequency problem' in a Bayesian environment is to add one to the count for every attribute value-class combination when an attribute value doesn't occur with every class value. This is how we'll get rid of getting a zero probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36821c6e",
   "metadata": {},
   "source": [
    "    How does Naive Bayes handle missing data?\n",
    "        Naive Bayes typically ignores missing data during calculation and makes predictions based on the available information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d1cc50",
   "metadata": {},
   "source": [
    "    How to evaluate the performance of a Naive Bayes classifier?\n",
    "        Common accuracy, precision, recall, F1-score, and area under the ROC curve (AUC), depending on the problem and class distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6087a6fc",
   "metadata": {},
   "source": [
    "    posterior,likelihood, prior and evidence?\n",
    "        Posterior probability represents an updated estimate of the probability of an event or variable, given new information or data.\n",
    "    \n",
    "         Likelihood represents the probability of observing the data given a particular class.\n",
    "         \n",
    "         Prior probabilities (P(y)) represent the prior knowledge of the class distribution in the dataset. \n",
    "         Evidence represents the overall probability of observing the data under all possible hypotheses or events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0701e2cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
