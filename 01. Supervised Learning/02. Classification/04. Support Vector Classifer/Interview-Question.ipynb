{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a73bc2d9",
   "metadata": {},
   "source": [
    "    what SVM?\n",
    "        Support vector machines (SVMs) are a set of supervised learning methods used for classification, regression and outliers detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d1ace1",
   "metadata": {},
   "source": [
    "    Why is it called support vector machine?\n",
    "        Since the separating hyperplane is supported (defined) by the vectors (data points) nearest the margin, so the algorithm is called SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37289e2e",
   "metadata": {},
   "source": [
    "    What are the kernals in SVM?\n",
    "        Kernels are a fundamental component that has the ability to handle complex, non linear boundaries.\n",
    "        Kernels provide shortcuts to avoid complex calculations. \n",
    "        They can transform low-dimensional input space into a higher-dimensional space. This can help convert non-separable problems into separable problems. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3f2357",
   "metadata": {},
   "source": [
    "    Types of Kernals?\n",
    "        Linear Kernel (Identity Kernel):\n",
    "            K(x, y) = x^T y\n",
    "            This kernel performs no transformation and is equivalent to using a linear classifier in the original feature space.\n",
    "            \n",
    "        Polynomial Kernel:\n",
    "            K(x, y) = (x^T y + c)^d\n",
    "            This kernel maps data into a higher-dimensional space using polynomial functions of degree 'd'.\n",
    "        \n",
    "        Radial Basis Function (RBF) Kernel:\n",
    "            K(x, y) = exp(-γ ||x - y||^2)\n",
    "            The RBF kernel maps data into an infinite-dimensional space and is often used when the decision boundary is expected to be non-linear and smooth.\n",
    "        \n",
    "        Sigmoid Kernel:\n",
    "            K(x, y) = tanh(α x^T y + c)\n",
    "            This kernel is based on the hyperbolic tangent function and can be useful in some scenarios, although it is less commonly used than linear, polynomial, or RBF kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f1662d",
   "metadata": {},
   "source": [
    "    what is C parameter in SVM?\n",
    "        THe \"C\" parameter in SVM controls the balance between maximizing the margin and minimizing training errors.\n",
    "        \n",
    "        Small C value (Closely resembling Hard Margin SVM)\n",
    "        Large C value (Closely resembling Soft Margin SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de38202e",
   "metadata": {},
   "source": [
    "    what is Hard Margin and Soft margin in SVM?\n",
    "        Hard margin SVM aims to find a hyperplane that perfectly separates the two classes in the training data without any misclassifications.(without overlap)\n",
    "        \n",
    "        The hard margin SVM seeks to maximize the margin, which is the distance between the hyperplane and the nearest data points (support vectors) from each class. This margin is also known as the \"hard margin.\"\n",
    "        \n",
    "        Soft margin SVM relaxes the requirement of perfect separation and allows for some misclassifications (margin violations) in the training data.(with overlap)\n",
    "        \n",
    "        The soft margin SVM introduces a regularization parameter, often denoted as \"C,\" which controls the trade-off between maximizing the margin and minimizing the classification errors. A smaller value of C allows for a wider margin and more misclassifications, while a larger value of C results in a narrower margin but fewer misclassifications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bf80dd",
   "metadata": {},
   "source": [
    "    What are support vectors in SVM?\n",
    "        Support vectors are the data points that are closest to the decision boundary in SVM.\n",
    "        \n",
    "        They are crucial for defining the margin and determining the position of the hyperplane."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f05e5c",
   "metadata": {},
   "source": [
    "    What is the hinge loss function?\n",
    "        It's measures the difference between the predicted score and the true label, taking into account a margin parameter.\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702d8c86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8f0457",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69283684",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a10441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cdaed2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926b784d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04eacf98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b33481b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18144351",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ae8781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c736dda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e49b00d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c710778",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
